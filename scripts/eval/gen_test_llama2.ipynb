{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPxYLaE9ZHgw"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and prepare dataset"
      ],
      "metadata": {
        "id": "JEabG2DbbBiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import random\n",
        "import re\n",
        "import csv\n",
        "from datetime import datetime\n",
        "import random\n",
        "import copy"
      ],
      "metadata": {
        "id": "QEHs_-CXoMXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_stories_dataset = load_dataset(\"roneneldan/TinyStories\", split=\"validation\")\n",
        "# SlimOrca_dataset = load_dataset(\"Open-Orca/SlimOrca\")\n",
        "truthful_qa_dataset = load_dataset(\"truthful_qa\", \"generation\", split=\"validation\")\n",
        "sciq_dataset = load_dataset(\"sciq\", split=\"test\")\n",
        "wikipedia_dataset = load_dataset(\"wikimedia/wikipedia\", \"20231101.en\")"
      ],
      "metadata": {
        "id": "8g9BKRYrz7-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "XkVGcSj4STVS"
      }
    },
    {
      "source": [
        "def normalize_string(text):\n",
        "  \"\"\"\n",
        "  Normalizes a string by removing leading and trailing whitespace, double spaces, and whitespace before symbols.\n",
        "  Args:\n",
        "    text: The string to normalize.\n",
        "  Returns:\n",
        "    The normalized string.\n",
        "  \"\"\"\n",
        "\n",
        "  # Remove leading and trailing whitespace.\n",
        "  text = text.strip()\n",
        "\n",
        "  # Remove whitespace before symbols.\n",
        "  while re.search(r'\\s([\\'\\\".,!?])', text):\n",
        "    text = re.sub(r'\\s([\\'\\\".,!?])', r'\\1', text)\n",
        "\n",
        "  # Remove double spaces.\n",
        "  text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "  return text"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "imWHrm9_Jte0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sr = normalize_string(\"This is an  ' s sentence      .  I 'm Tien  \")\n",
        "print(sr)\n",
        "sne01 = normalize_string(\"This   is an     sentence. I'm Tien      \")\n",
        "print(sne01)\n",
        "sne02 = normalize_string(\"This   is an     sentence. I'm      Tien !!!    \")\n",
        "print(sne02)"
      ],
      "metadata": {
        "id": "XdKKE48LMOBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_prompts_to_file(filename, dataset, num_samples, seq_len, prompt_key,\n",
        "                          metadata_keys, is_question=False):\n",
        "  \"\"\"\n",
        "  Select random prompts from a dataset and write them to a file.\n",
        "\n",
        "  Args:\n",
        "    filename: The name of the file to write to.\n",
        "    dataset: The list prompts to choose indices.\n",
        "    num_samples: The number of prompts to write.\n",
        "    seq_len: The maximum length of the prompts.\n",
        "    prompt_key: The key in the dataset that contains the prompts.\n",
        "    metadata_keys: The keys in the dataset that contain metadata.\n",
        "    is_question: Whether the prompts are questions or not.\n",
        "  \"\"\"\n",
        "  # Open and init write file\n",
        "  in_file_path = filename + f\"_{num_samples}.txt\"\n",
        "  meta_file_path = filename + f\"_{num_samples}_metadata.csv\"\n",
        "  in_file = open(in_file_path, 'w')\n",
        "  meta_file = open(meta_file_path, 'w')\n",
        "\n",
        "  metadatas = []\n",
        "  # Generate a random prompts from dataset.\n",
        "  random_prompts = random.choices(dataset, k=num_samples)\n",
        "  in_file.write(f\"{num_samples}\\n\")\n",
        "  # Write the prompts to the file.\n",
        "  for sample in random_prompts:\n",
        "    if not is_question:\n",
        "      # Remove \"\\n\" character\n",
        "      sample[prompt_key] = sample[prompt_key].replace(\"\\n\", \" \")\n",
        "      # Split the prompt into words\n",
        "      sentence_words = sample[prompt_key].split(\" \")\n",
        "      ub = min(len(sentence_words), seq_len)\n",
        "      # Random sampling indices at least 5 words to upper bound of prompt\n",
        "      cutoff_index = random.randrange(5, ub)\n",
        "      prompt = \" \".join(sentence_words[:cutoff_index])\n",
        "    else:\n",
        "      prompt = sample[prompt_key]\n",
        "\n",
        "    # Write the prompts to the in file.\n",
        "    in_file.write(prompt + \"\\n\")\n",
        "\n",
        "    metadata = {\n",
        "      \"prompt\": prompt,\n",
        "    }\n",
        "    for key in metadata_keys:\n",
        "      metadata[key] = sample[key]\n",
        "    metadatas.append(metadata)\n",
        "\n",
        "  # write promts with metadata\n",
        "  meta_writer = csv.DictWriter(meta_file, fieldnames=metadatas[0].keys())\n",
        "  meta_writer.writeheader()\n",
        "  for metadata in metadatas:\n",
        "    meta_writer.writerow(metadata)\n",
        "\n",
        "  in_file.close()\n",
        "  meta_file.close()"
      ],
      "metadata": {
        "id": "kNkPjperlvix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sciq dataset"
      ],
      "metadata": {
        "id": "9vPmnESbSN1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sciq_dataset)"
      ],
      "metadata": {
        "id": "PuqxDctK_r87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(sciq_dataset[i]['question'])"
      ],
      "metadata": {
        "id": "dnJvY6NEipNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_prompts_to_file(\"sciq_in\", sciq_dataset, 256, 1024, \"question\", [\"correct_answer\", \"support\"], is_question=True)"
      ],
      "metadata": {
        "id": "dPkgKPScuQBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TinyStories dataset"
      ],
      "metadata": {
        "id": "rqaHu4wRSPe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tiny_stories_dataset)"
      ],
      "metadata": {
        "id": "DuVn6zPogZma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(tiny_stories_dataset[i]['text'])\n",
        "# tiny_stories_dataset.features['text']"
      ],
      "metadata": {
        "id": "mpbaGTiVgP-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_prompts_to_file(\"tinystories_in\", tiny_stories_dataset, 256, 1024, \"text\", [\"text\"], is_question=False)"
      ],
      "metadata": {
        "id": "FsAZLvnuvxPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## truthful_qa dataset"
      ],
      "metadata": {
        "id": "BNNIECofSdso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(truthful_qa_dataset)"
      ],
      "metadata": {
        "id": "o1jq2mOWXeBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(truthful_qa_dataset[i]['question'])"
      ],
      "metadata": {
        "id": "NKhg9sz-lG4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_prompts_to_file(\"truthful_qa_in\", truthful_qa_dataset, 256, 1024, \"question\", [\"best_answer\", \"correct_answers\", \"source\"], is_question=True)"
      ],
      "metadata": {
        "id": "bqUR6mgLdV4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### wikipedia dataset"
      ],
      "metadata": {
        "id": "_Z1zpgfeUDde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(wikipedia_dataset)"
      ],
      "metadata": {
        "id": "2D2RDxGTXexj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  print(f\"===== {wikipedia_dataset['train'][i]['title']} =====\")\n",
        "  print(wikipedia_dataset['train'][i]['text'])"
      ],
      "metadata": {
        "id": "4wz9b1c5l_EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_prompts_to_file(\"wikipedia_in\", wikipedia_dataset['train'], 256, 1024, \"text\", [\"text\"], is_question=False)"
      ],
      "metadata": {
        "id": "rln098E5rCmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SlimOrca dataset (Not usefull)"
      ],
      "metadata": {
        "id": "VqY9eOe3Sda0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(SlimOrca_dataset)\n",
        "print(SlimOrca_dataset['train'][0]['conversations'][0])"
      ],
      "metadata": {
        "id": "Q8VPTiNbXdqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(f\"===== {i} =====\")\n",
        "    for content in SlimOrca_dataset['train'][i]['conversations']:\n",
        "      print(content)"
      ],
      "metadata": {
        "id": "DcfTu_lqkRm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parse_SlimOrca_dataset = []\n",
        "for sample in SlimOrca_dataset['train']:\n",
        "  in_sample = {\n",
        "      \"instruction\": \"\",\n",
        "      \"response\": \"\"\n",
        "  }\n",
        "  for content in sample['conversations']:\n",
        "    # if content['from'] == 'system':\n",
        "    #   in_sample['instruction'] = content['value'] + in_sample['instruction']\n",
        "    if content['from'] == 'human':\n",
        "      in_sample['instruction'] += \" \" + content['value']\n",
        "    else:\n",
        "      in_sample['response'] = content['value']  # GPT response\n",
        "\n",
        "  parse_SlimOrca_dataset.append(in_sample)"
      ],
      "metadata": {
        "id": "zBGY1KQTkHft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(parse_SlimOrca_dataset[i])"
      ],
      "metadata": {
        "id": "8z9nKhLwlypo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_prompts_to_file(\"SlimOrca_in\", parse_SlimOrca_dataset, 128, 1024, \"instruction\", [\"response\"], is_question=True)"
      ],
      "metadata": {
        "id": "WrrlbZaEj5ep"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}